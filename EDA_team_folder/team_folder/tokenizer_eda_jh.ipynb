{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
      "        num_rows: 3952\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
      "        num_rows: 240\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import DatasetDict, load_from_disk, load_metric\n",
    "from arguments import DataTrainingArguments, ModelArguments\n",
    "import numpy as np\n",
    "datasets = load_from_disk(\"../data/train_dataset\")\n",
    "print(datasets)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uomnf97/klue-roberta-finetuned-korquad-v2\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = datasets[\"train\"][\"question\"]\n",
    "context = datasets[\"train\"][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2500 # 겹치는 부분이 없도록, 데이터 확인을 위해서 크게 잡음\n",
    "doc_stride = 128\n",
    "tokenized_examples = tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            truncation=\"only_second\",\n",
    "            max_length=max_seq_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_token_type_ids=False, # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "            padding=\"max_length\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token ID: 0\n",
      "[SEP] token ID: 2\n",
      "[PAD] token ID: 1\n",
      "[UNK] token ID: 3\n",
      "[MASK] token ID: 4\n"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.cls_token_id\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "unk_token_id = tokenizer.unk_token_id\n",
    "mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "print(f\"[CLS] token ID: {cls_token_id}\")\n",
    "print(f\"[SEP] token ID: {sep_token_id}\")\n",
    "print(f\"[PAD] token ID: {pad_token_id}\")\n",
    "print(f\"[UNK] token ID: {unk_token_id}\")\n",
    "print(f\"[MASK] token ID: {mask_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11 ~ 12세기에 제작된 본존불은 보통 어떤 나라의 특징이 전파되었나요? 불상을 모시기 위해 나무나 돌, 쇠 등을 깎아 일반적인 건축물보다 작은 규모로 만든 것을 불감 ( 佛 ) 이라고 한다. 불감은 그 안에 모신 불상의 양식뿐만 아니라, 당시의 건축 양식을 함께 살필 수 있는 중요한 자료가 된다. n n이 작품은 높이 18cm의 작은 불감으로, 청동으로 불감과 불상을 만들고 그 위에 금칠을 하였다. 불감 내부를 살펴보면 난간을 두른 사각형의 기단 위에 본존불과 양 옆에 보살상이 있으며, 그 위에 기둥과 지붕으로 된 뚜껑이 덮혀 있다. 법당 모양의 뚜껑에는 앞면과 양쪽에 커다란 창문이 있어서 안에 모셔진 불상을 잘 볼 수 있도록 하였다. n n본존불은 얼굴이 추상적이고, 양 어깨를 감싸고 있는 옷은 주름을 간략한 선으로 표현했다. 몸 뒤편에 있는 광배 ( 光 ) 는 머리광배와 몸광배로 나누어져 있으며, 불꽃무늬로 가장자리를 장식하고 있다. 본존불 양 옆의 보살상도 구슬로 장식된 관 ( ) 을 쓰고 있다는 점을 제외하면 형식이나 표현 수법이 본존불과 유사하다. n n불감은 지금도 금색이 찬란하고 지붕에 녹청색이 남아 있는 등 전체적인 보존 상태가 양호하다. 본존불의 긴 허리, 불규칙하게 나타나는 옷주름, 그리고 보살이 쓰고 있는 구슬로 장식한 관 ( ) 등 여러 양식으로 보아 만든 시기는 중국 북방 계통의 영향을 받은 11∼12세기 경으로 추정된다. 이 작품은 고려시대 또는 그 이전의 목조건축 양식과 조각수법을 보여주는 귀중한 예라는 점에서 가치가 크다고 할 수 있다.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decoding\n",
    "example = tokenized_examples[\"input_ids\"][3]\n",
    "decoded_text = tokenizer.decode(example, skip_special_tokens=True)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3952, 2500)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tokenized_examples[\"input_ids\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대응되는 토큰들 확인\n",
    "\n",
    "Special Tokens\n",
    "* [CLS] token ID: 0\n",
    "* [SEP] token ID: 2\n",
    "* [PAD] token ID: 1\n",
    "* [UNK] token ID: 3\n",
    "* [MASK] token ID: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_ids_to_tokens(tokenizer, tokenized_examples):\n",
    "    tokenized_data = []\n",
    "    for input_id_list in tokenized_examples[\"input_ids\"]:\n",
    "        # input_ids 리스트를 다시 토큰으로 변환\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "        tokenized_data.append(tokens)\n",
    "    \n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = np.array(convert_input_ids_to_tokens(tokenizer, tokenized_examples=tokenized_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3845, 2125, 4004, 2446, 2084, 7604, 2079, 25087, 2052, 860, 1644, 2073, 35, 2, 11, 5496, 2125, 11984, 11, 4013, 11, 6725, 2125, 11984, 11, 3604, 3845, 2125, 11984, 6233, 4561, 2496, 2259, 4342, 2259, 9746, 2440, 2104, 28674, 18, 22, 2232, 3665, 2104, 2165, 2069, 4372, 2088, 16, 26, 18, 3912, 23249, 2079, 4342, 2200, 4227, 2073, 7087, 6968, 2170, 4154, 19521, 16, 4227, 12617, 2079, 8400, 2116, 4751, 7488, 6815, 16, 4501, 16, 9583, 7606, 27135, 10035, 2226, 2116, 2116, 4605, 2496, 2259, 4342, 2507, 2088, 16, 3666, 2073, 4175, 3719, 3674, 2125, 3908, 2170, 3646, 2052, 6670, 2069, 3645, 1889, 2414, 4342, 2507, 2062, 18, 3727, 19011, 2440, 11358, 4077, 2506, 2079, 9698, 170, 3939, 2079, 3966, 171, 793, 3845, 2125, 3939, 2079, 3872, 2069, 4277, 7488, 2112, 16, 4078, 5496, 2125, 4004, 2446, 2084, 7604, 2138, 11750, 3845, 2125, 4004, 2446, 2084, 7604, 2079, 18773, 2052, 3622, 18, 4077, 2506, 2259, 7097, 2079, 4008, 2069, 3986, 2205, 2307, 3939, 2052, 30142, 2104, 3841, 2079, 4145, 2052, 2155, 4038, 2052, 7245, 3831, 2205, 2507, 2088, 16, 1504, 3831, 2073, 4041, 14223, 4004, 2446, 2084, 7604, 2079, 4008, 2069, 9973, 2371, 2062, 18, 3, 81, 3, 81, 2056, 2104, 2125, 4004, 2446, 2084, 7604, 2522, 5496, 4004, 2446, 2084, 7604, 2079, 3676, 1751, 4193, 2259, 4185, 28674, 18, 3630, 14223, 2079, 3979, 2069, 1122, 2414, 5496, 2125, 11984, 12, 6725, 2125, 3939, 13, 1503, 5203, 2073, 4039, 2069, 3986, 2205, 2507, 3683, 16, 9746, 2440, 2104, 3719, 2079, 3845, 11984, 2073, 4185, 2069, 3986, 2205, 2507, 2062, 18, 4039, 2052, 13740, 2897, 11, 5276, 31221, 3646, 2446, 2084, 11, 3923, 27135, 3757, 2470, 4039, 2069, 4004, 2446, 2084, 7604, 2079, 4300, 16, 3939, 2079, 4300, 2069, 3961, 3757, 2470, 3993, 2138, 4185, 7488, 11, 5967, 2125, 3646, 4001, 11, 3923, 2200, 4561, 2496, 2359, 2062, 18, 1504, 4185, 2125, 4872, 14149, 2073, 3747, 16, 4119, 16, 3706, 2069, 3886, 6233, 1889, 2259, 4004, 2446, 2084, 7604, 3981, 2069, 4605, 2371, 2062, 18, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_examples[\"input_ids\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNK 토큰 개수 확인 (Question, Context) - Train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unknown(tokenized_samples):\n",
    "    # tokenized_samples = [\"input_ids\"] 리스트들\n",
    "    unk_count_per_index = []\n",
    "    for i,sample in enumerate(tokenized_samples):\n",
    "        sample_unk_count = 0\n",
    "        for token in sample:\n",
    "            if token == 3: # unk token ids\n",
    "                sample_unk_count += 1\n",
    "        \n",
    "        unk_count_per_index.append([i, sample_unk_count])\n",
    "\n",
    "    return np.array(unk_count_per_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_token = check_unknown(tokenized_examples[\"input_ids\"]) # [질문,지문]별 UNK 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28343\n"
     ]
    }
   ],
   "source": [
    "# 전체 context에 대한 UNK Token\n",
    "print(np.sum(unk_token[:,1],axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown token외에 문제점이 보이는 token 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"[CLS]\",\"[PAD]\",\"[SEP]\",\"[MASK]\"]\n",
    "def get_encoded_data(data, index):\n",
    "    tokens = []\n",
    "    for i,token in enumerate(data[index]):\n",
    "        if token in special_tokens:\n",
    "            continue\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은? 미국 상의원 또는 미국 상원(United States Senate)은 양원제인 미국 의회의 상원이다.\\n\\n미국 부통령이 상원의장이 된다. 각 주당 2명의 상원의원이 선출되어 100명의 상원의원으로 구성되어 있다. 임기는 6년이며, 2년마다 50개주 중 1/3씩 상원의원을 새로 선출하여 연방에 보낸다.\\n\\n미국 상원은 미국 하원과는 다르게 미국 대통령을 수반으로 하는 미국 연방 행정부에 각종 동의를 하는 기관이다. 하원이 세금과 경제에 대한 권한, 대통령을 포함한 대다수의 공무원을 파면할 권한을 갖고 있는 국민을 대표하는 기관인 반면 상원은 미국의 주를 대표한다. 즉 캘리포니아주, 일리노이주 같이 주 정부와 주 의회를 대표하는 기관이다. 그로 인하여 군대의 파병, 관료의 임명에 대한 동의, 외국 조약에 대한 승인 등 신속을 요하는 권한은 모두 상원에게만 있다. 그리고 하원에 대한 견제 역할(하원의 법안을 거부할 권한 등)을 담당한다. 2년의 임기로 인하여 급진적일 수밖에 없는 하원은 지나치게 급진적인 법안을 만들기 쉽다. 대표적인 예로 건강보험 개혁 당시 하원이 미국 연방 행정부에게 퍼블릭 옵션(공공건강보험기관)의 조항이 있는 반면 상원의 경우 하원안이 지나치게 세금이 많이 든다는 이유로 퍼블릭 옵션 조항을 제외하고 비영리건강보험기관이나 보험회사가 담당하도록 한 것이다. 이 경우처럼 상원은 하원이나 내각책임제가 빠지기 쉬운 국가들의 국회처럼 걸핏하면 발생하는 의회의 비정상적인 사태를 방지하는 기관이다. 상원은 급박한 처리사항의 경우가 아니면 법안을 먼저 내는 경우가 드물고 하원이 만든 법안을 수정하여 다시 하원에 되돌려보낸다. 이러한 방식으로 단원제가 빠지기 쉬운 함정을 미리 방지하는 것이다.날짜=2017-02-05\n",
      "대통령,##을,포함,##한,미국,##의,행정부,견제,##권,##을,갖,##는,국가,기관,##은,?,미국,상의,##원,또는,미국,상원,(,United,State,##s,Se,##n,##ate,),은,양,##원,##제,##인,미국,의회,##의,상원,##이다,.,[UNK],n,[UNK],n,##미,##국,부통령,##이,상원,##의,##장이,된다,.,각,주당,2,##명,##의,상원,##의원,##이,선출,##되,##어,100,##명,##의,상원,##의원,##으로,구성,##되,##어,있,##다,.,임기,##는,6,##년,##이,##며,,,2,##년,##마다,50,##개,##주,중,1,/,3,##씩,상원,##의원,##을,새로,선출,##하여,연방,##에,보낸다,.,[UNK],n,[UNK],n,##미,##국,상원,##은,미국,하원,##과,##는,다르,##게,미국,대통령,##을,수반,##으로,하,##는,미국,연방,행정부,##에,각종,동의,##를,하,##는,기관,##이다,.,하원,##이,세금,##과,경제,##에,대한,권한,,,대통령,##을,포함,##한,대다수,##의,공무원,##을,파면,##할,권한,##을,갖,##고,있,##는,국민,##을,대표,##하,##는,기관,##인,반면,상원,##은,미국,##의,주,##를,대표,##한다,.,즉,캘리포니아주,,,일리,##노이,##주,같이,주,정부,##와,주,의회,##를,대표,##하,##는,기관,##이다,.,그로,인하,##여,군대,##의,파병,,,관료,##의,임명,##에,대한,동의,,,외국,조약,##에,대한,승인,등,신속,##을,요하,##는,권한,##은,모두,상원,##에,##게,##만,있,##다,.,그리고,하원,##에,대한,견제,역할,(,하원,##의,법안,##을,거부,##할,권한,등,),을,담당,##한다,.,2,##년,##의,임기,##로,인하,##여,급진,##적,##일,수,##밖,##에,없,##는,하원,##은,지나치,##게,급진,##적인,법안,##을,만들,##기,쉽,##다,.,대표,##적인,예,##로,건강,##보험,개혁,당시,하원,##이,미국,연방,행정부,##에,##게,퍼블,##릭,옵션,(,공공,##건,##강,##보험,##기,##관,),의,조항,##이,있,##는,반면,상원,##의,경우,하원,##안,##이,지나치,##게,세금,##이,많이,든다는,이유로,퍼블,##릭,옵션,조항,##을,제외,##하고,비,##영,##리,##건,##강,##보험,##기,##관,##이나,보험,##회사,##가,담당,##하,##도록,한,것,##이다,.,이,경우,##처럼,상원,##은,하원,##이나,내각,##책,##임,##제,##가,빠지,##기,쉬운,국가,##들,##의,국회,##처럼,걸,##핏,##하면,발생,##하,##는,의회,##의,비정,##상,##적인,사태,##를,방지,##하,##는,기관,##이다,.,상원,##은,급박,##한,처리,##사항,##의,경우,##가,아니면,법안,##을,먼저,내,##는,경우,##가,드물,##고,하원,##이,만든,법안,##을,수정,##하여,다시,하원,##에,되돌려,##보,##낸다,.,이러,##한,방식,##으로,단원,##제,##가,빠지,##기,쉬운,함정,##을,미리,방지,##하,##는,것,##이다,.,날짜,=,2017,-,02,-,05\n",
      "number of UNK token : [0 4]\n"
     ]
    }
   ],
   "source": [
    "special_tokens = [\"[CLS]\",\"[PAD]\",\"[SEP]\",\"[MASK]\"] \n",
    "print(datasets[\"train\"][\"question\"][0], datasets[\"train\"][\"context\"][0])\n",
    "print(\",\".join(get_encoded_data(tokenized_data, 0)))\n",
    "print(\"number of UNK token :\", unk_token[0]) # 총 4개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일본어, 한자 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['명문이 적힌 유물을 구성하는 그릇의 총 개수는?']\n",
      "['동아대학교박물관에서 소장하고 있는 계사명 사리구는 총 4개의 용기로 구성된 조선후기의 유물로, 경상남도 울주군 웅촌면 대복리에서 '\n",
      " '출토되었다고 전한다',\n",
      " ' 외함(外函)은 청화명문이 있는 백자이며, 그 안쪽에 납작한 금속제 원형 합 2점과 금속제 원통형 합 등 3점의 그릇이 봉안되어 있다',\n",
      " '\\\\n\\\\n바깥쪽의 외함인 백자 합 동체 중앙부 표면에 청화안료로 쓴 “癸巳二月日 施主承表 兩主”라는 명문이 세로로 세 줄에 걸쳐서 쓰여 '\n",
      " '있어 조선 후기인 계사년에 시주자인 승표 부부가 발원하여 만든 것임을 알 수 있다',\n",
      " '\\\\n\\\\n동아대학교박물관의 계사명 사리구는 정확한 제작연대는 알 수 없지만 명문 등을 통해 적어도 17세기 이후에 제작된 것으로 '\n",
      " '추정되는 작품으로, 명문이 있는 조선 후기 경상도 지역 출토 사리장엄구라는 점에서 중요한 가치를 지닌 작품으로 판단된다',\n",
      " '\\\\n\\\\n조선 후기 사리장엄구는 아직까지 조사와 연구가 거의 이루어지지 않았으나, 이처럼 세트를 갖추어 출토된 유물은 비교적 드문 '\n",
      " '편임을 고려할 때, 이 계사명 사리장엄구는 제작연대와 발원자의 이름이 밝혀져 있으며, 지금까지 출토된 예가 드문 비교적 완전한 세트를 '\n",
      " '가진 유물이라는 점에서 조선 후기 사리장엄구 연구에 자료적 가치를 지닌 유물이다',\n",
      " '']\n",
      "----Tokenize----\n",
      "'명문,##이,적힌,유물,##을,구성,##하,##는,그릇,##의,총,개수,##는,?,동아,##대,##학교,##박,##물,##관,##에서,소장,##하고,있,##는,계,##사,##명,사리,##구,##는,총,4,##개,##의,용기,##로,구성,##된,조선,##후,##기,##의,유물,##로,,,경상남도,울주군,웅,##촌,##면,대,##복,##리에,##서,출토,##되,##었,##다고,전한다,.,외,##함,(,外,[UNK],),은,청,##화,##명,##문,##이,있,##는,백자,##이,##며,,,그,안쪽,##에,납작,##한,금속,##제,원형,합,2,##점,##과,금속,##제,원통,##형,합,등,3,##점,##의,그릇,##이,봉안,##되,##어,있,##다,.,[UNK],n,[UNK],n,##바,##깥,##쪽,##의,외,##함,##인,백자,합,동,##체,중앙,##부,표면,##에,청,##화,##안,##료,##로,쓴,“,[UNK],[UNK],二,月,日,[UNK],主,[UNK],表,[UNK],主,”,라는,명문,##이,세로,##로,세,줄,##에,걸쳐서,쓰여,있,##어,조선,후기,##인,계,##사,##년,##에,시,##주,##자,##인,승,##표,부부,##가,발원,##하여,만든,것,##임,##을,알,수,있,##다,.,[UNK],n,[UNK],n,##동아,##대,##학교,##박,##물,##관,##의,계,##사,##명,사리,##구,##는,정확,##한,제작,##연대,##는,알,수,없,##지만,명문,등,##을,통해,적어도,17,##세기,이후,##에,제작,##된,것,##으로,추정,##되,##는,작품,##으로,,,명문,##이,있,##는,조선,후기,경상도,지역,출토,사리,##장,##엄,##구,##라는,점,##에서,중요,##한,가치,##를,지닌,작품,##으로,판단,##된,##다,.,[UNK],n,[UNK],n,##조선,후기,사리,##장,##엄,##구,##는,아직,##까,##지,조사,##와,연구,##가,거의,이루어지,##지,않,##았,##으나,,,이,##처럼,세트,##를,갖추,##어,출토,##된,유물,##은,비교,##적,드문,편,##임,##을,고려,##할,때,,,이,계,##사,##명,사리,##장,##엄,##구,##는,제작,##연대,##와,발원,##자,##의,이름,##이,밝혀져,있,##으며,,,지금,##까,##지,출토,##된,예,##가,드문,비교,##적,완전,##한,세트,##를,가진,유물,##이,##라는,점,##에서,조선,후기,사리,##장,##엄,##구,연구,##에,자료,##적,가치,##를,지닌,유물,##이다,.'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# 예시 데이터\n",
    "pprint(datasets[\"train\"][\"question\"][4].split(\".\"))\n",
    "pprint(datasets[\"train\"][\"context\"][4].split(\".\"))\n",
    "print(\"----Tokenize----\")\n",
    "pprint(\",\".join(get_encoded_data(tokenized_data, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 12])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 예시에 대한 unk 개수\n",
    "unk_token[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한자를 대부분 잘 못알아 보는 것을 확인할 수 있다. 그렇다면 이 한자를 어떻게 해야하는가..? Answer에 한자가 포함된 경우를 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_start': [202], 'text': ['‘전의식’(前意識)']}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][\"answers\"][136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['프로이트의 정신 체계에서 현실적인 정신체계와 본능적 충동의 체계를 제외한 것의 명칭은?']\n",
      "['프로이트는 꿈을 해석해서 참다운 꿈 생각을 밝혀낼 수 있다고 믿었다',\n",
      " ' 또한 환자와 허물없는 대화를 나누는 자유연상법에 따라 환자의 말을 해석함으로써 환자를 정신적 억압으로부터 해방시키고 치료할 수 있다고 '\n",
      " '믿었다',\n",
      " ' 반복 강박을 비롯한 삶의 충동과 죽음의 충동에 대한 예리한 통찰을 바로 이 책을 통해 엿볼 수 있다',\n",
      " '\\\\n\\\\n우선 프로이트는 정신의 체계를 ‘의식’, ‘전의식’(前意識), ‘무의식’의 세 가지로 구분하여 보았다',\n",
      " ' 의식은 원래 의식된 것으로서 이성적, 합리적, 현실적인 정신의 체계에 해당한다',\n",
      " ' 무의식은 의식되지 않은 것으로서 정신 과정의 대부분을 차지하는 무의식적인 본능적 충동의 체계다',\n",
      " ' 그런가 하면 전의식은 의식되기 이전의 정신 체계로서 무의식을 걸러서 의식 쪽으로 보내는 역할, 곧 검열을 행하는 정신의 체계다',\n",
      " '\\\\n\\\\n≪꿈의 해석≫에서 프로이트는 ‘의식’, ‘전의식’, ‘무의식’에 관해서 아직 철저하게 해명하지 못하고 있다',\n",
      " ' 따라서 그는 이 책 아울러 1923년에 출판한 ≪자아와 이드≫에서 정신 과정을 보다 더 명확하고 철저하게 밝힌다',\n",
      " ' 이 책에서 프로이트는 ‘의식’, ‘전의식’, ‘무의식’을 하나의 의식이라고 말한다',\n",
      " ' 곧 의식의 가장 많은 부분을 무의식이 차지하고 있고 가장 적은 부분을 전의식이 차지하고 있으며 이성적 현실 의식 역시 부분적이라는 '\n",
      " '것이다',\n",
      " ' 그런가 하면 ≪자아와 이드≫에서 프로이트는 정신 과정을 ‘원초아’, ‘자아’, ‘초자아’로 구분하는데 이러한 구분은 이 책에서의 정신 '\n",
      " '과정을 한층 더 역동적으로 밝히고 있다',\n",
      " ' 본능 충동으로서의 원초아와 도덕 및 양심에 관계되는 초자아는 무의식에 해당하고 현실적 이성 활동은 자아에 속한다',\n",
      " ' ≪자아와 이드≫에서 프로이트는 에로스와 타나토스, 곧 ‘사랑의 충동’과 ‘죽음의 충동’을 대립시키는데 이것은 이 책서 전개한 삶의 '\n",
      " '충동과 죽음의 충동을 확대하여 발전시킨 것이라고 할 수 있다',\n",
      " ' 무엇보다도 프로이트는 인간의 정신 과정과 활동의 원천을 오직 쾌락 원리로 제한하려는 상식적인 견해를 해체하고 극복함으로써 쾌락 원리의 '\n",
      " '저편에서 정신 과정과 활동의 원천을 찾으려고 했다',\n",
      " ' 이 책에서는 ≪꿈의 해석≫과 ≪정신분석학 입문 강의≫를 기초로 하고 전개되는 프로이트 정신분석학의 말년의 사상을 충분히 엿보게 한다',\n",
      " '']\n",
      "----Tokenize----\n",
      "'프로이트,##의,정신,체계,##에서,현실,##적인,정신,##체,##계,##와,본능,##적,충동,##의,체계,##를,제외,##한,것,##의,명칭,##은,?,프로이트,##는,꿈,##을,해석,##해서,참,##다운,꿈,생각,##을,밝혀,##낼,수,있,##다고,믿,##었,##다,.,또한,환자,##와,허물,##없,##는,대화,##를,나누,##는,자유,##연,##상,##법,##에,따라,환자,##의,말,##을,해석,##함,##으로,##써,환자,##를,정신,##적,억압,##으로,##부터,해방,##시,##키,##고,치료,##할,수,있,##다고,믿,##었,##다,.,반복,강박,##을,비롯,##한,삶,##의,충동,##과,죽음,##의,충동,##에,대한,예리,##한,통찰,##을,바로,이,책,##을,통해,엿볼,수,있,##다,.,[UNK],n,[UNK],n,##우,##선,프로이트,##는,정신,##의,체계,##를,‘,의식,’,,,‘,전,##의식,’,(,前,意,[UNK],),,,‘,무의식,’,의,세,가지,##로,구분,##하여,보,##았,##다,.,의식,##은,원래,의식,##된,것,##으로,##서,이성,##적,,,합리,##적,,,현실,##적인,정신,##의,체계,##에,해당,##한다,.,무의식,##은,의식,##되,##지,않,##은,것,##으로,##서,정신,과정,##의,대부분,##을,차지,##하,##는,무의식,##적인,본능,##적,충동,##의,체계,##다,.,그런가,하,##면,전,##의식,##은,의식,##되,##기,이전,##의,정신,체계,##로,##서,무의식,##을,걸러,##서,의식,쪽,##으로,보내,##는,역할,,,곧,검열,##을,행하,##는,정신,##의,체계,##다,.,[UNK],n,[UNK],n,##≪,##꿈,##의,해석,##≫,##에서,프로이트,##는,‘,의식,’,,,‘,전,##의식,’,,,‘,무의식,’,에,관해서,아직,철저,##하,##게,해명,##하,##지,못하,##고,있,##다,.,따라서,그,##는,이,책,아울러,1923,##년,##에,출판,##한,≪,##자,##아,##와,이드,##≫,##에서,정신,과정,##을,보다,더,명확,##하고,철저,##하,##게,밝힌다,.,이,책,##에서,프로이트,##는,‘,의식,’,,,‘,전,##의식,’,,,‘,무의식,’,을,하나,##의,의식,##이,##라고,말,##한다,.,곧,의식,##의,가장,많,##은,부분,##을,무의식,##이,차지,##하고,있,##고,가장,적,##은,부분,##을,전,##의식,##이,차지,##하고,있,##으며,이성,##적,현실,의식,역시,부분,##적,##이,##라는,것,##이다,.,그런가,하,##면,≪,##자,##아,##와,이드,##≫,##에서,프로이트,##는,정신,과정,##을,‘,원초,##아,’,,,‘,자아,’,,,‘,초,##자,##아,’,로,구분,##하,##는데,이러,##한,구분,##은,이,책,##에서,##의,정신,과정,##을,한층,더,역동,##적으로,밝히,##고,있,##다,.,본능,충동,##으로,##서,##의,원초,##아,##와,도덕,및,양심,##에,관계,##되,##는,초,##자,##아,##는,무의식,##에,해당,##하고,현실,##적,이성,활동,##은,자아,##에,속한다,.,≪,##자,##아,##와,이드,##≫,##에서,프로이트,##는,에로,##스,##와,타,##나,##토스,,,곧,‘,사랑,##의,충동,’,과,‘,죽음,##의,충동,’,을,대립,##시,##키,##는데,이것,##은,이,책,##서,전개,##한,삶,##의,충동,##과,죽음,##의,충동,##을,확대,##하여,발전,##시,##킨,것,##이,##라고,할,수,있,##다,.,무엇,##보,##다,##도,프로이트,##는,인간,##의,정신,과정,##과,활동,##의,원천,##을,오직,쾌락,원리,##로,제한,##하,##려,##는,상식,##적인,견해,##를,해체,##하고,극복,##함,##으로,##써,쾌락,원리,##의,저편,##에서,정신,과정,##과,활동,##의,원천,##을,찾,##으,##려고,했,##다,.,이,책,##에서,##는,≪,##꿈,##의,해석,##≫,##과,≪,##정신,##분석,##학,입문,강의,##≫,##를,기초,##로,하고,전개,##되,##는,프로이트,정신,##분석,##학,##의,말년,##의,사상,##을,충분히,엿보,##게,한다,.'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# 예시 데이터\n",
    "pprint(datasets[\"train\"][\"question\"][136].split(\".\"))\n",
    "pprint(datasets[\"train\"][\"context\"][136].split(\".\"))\n",
    "print(\"----Tokenize----\")\n",
    "pprint(\",\".join(get_encoded_data(tokenized_data, 136)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 데이터를 보면 확실히 한자에 대한 tokenizing이 제대로 이루어지지 않음을 볼 수 있다.\n",
    "\n",
    "이렇다면 생각나는 문제점은.. 학습이 제대로 되지않아 만약에 한자가 또 들어오면 정답을 제대로 못낼 수 있다는 단점이 있다..\n",
    "\n",
    "오히려 특수문자, \"<< >>\"는 제대로 Tokenizing하는 것을 볼 수 있음\n",
    "\n",
    "만약에 답이 특수문자가 되는 경우에는 어떻게 나오는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['천연두에 감염된 모든 사례 중 출혈성 천연두는 얼마의 비중을 차지하는가?']\n",
      "['출혈성 천연두는 피부, 점막, 소화관에 광범한 내출혈을 동반하는 심각한 천연두 유형이다',\n",
      " ' 출혈성 천연두는 전체 천연두 감염 사례의 약 2% 정도였으며, 대부분 성인에게 발병했다 출혈성 천연두의 발진은 수포를 형성하지 않고 '\n",
      " '부드러운 상태로 남아 있다',\n",
      " ' 대신 피부 아래로 출혈이 일어나서 마치 새까맣게 탄 것처럼 검은색을 띤다 그래서 이 유형의 천연두를 검은마마(black pox)라고도 '\n",
      " '했다\\\\n\\\\n감염 초기, 또는 전격형(fulminating) 출혈성 천연두는, 감염 이틀째 내지 사흘째가 되면 결막하 출혈로 인해 눈의 '\n",
      " '흰자위가 심홍색이 되면서 출혈이 확인된다',\n",
      " ' 출혈성 천연두는 어스름한 홍반, 점상출혈 및 비장, 신장, 장막, 근육에 출혈을 일으키고, 드물지만 외심막, 간, 고환, 난소, '\n",
      " '방광에도 출혈을 일으킨다',\n",
      " ' 환자는 보통 감염 5 ~ 7일째 경미해 보이는 피부 발진만을 남기고 갑자기 죽는다',\n",
      " ' 전격형 출혈성 천연두는 8 ~ 10일 정도 생존한 환자들에게서 나타났다',\n",
      " ' 발진 초기에 출혈이 나타나며, 발진은 도드라지지 않고 평평하고 수포 단계 이상 발달하지 않는다 출혈성 천연두 초기 환자는 혈중 '\n",
      " '응고인자(e',\n",
      " 'g',\n",
      " ' 혈소판, 프로트롬빈, 글로불린)가 감소하고 안티트롬빈이 증가한다',\n",
      " ' 말기 환자는 확연한 혈소판감소증을 나타내지만 응고인자 감소는 덜 심하다',\n",
      " ' 말기 단계에서는 안티트롬빈 증가도 나타났다 천연두 유형의 병독성에 따라 이 유형의 천연두는 치명적 천연두 감염 사례의 3 ~ 25% '\n",
      " '정도로 잡힌다 출혈성 천연두는 대개 사망에 이를 정도로 치명적이다']\n",
      "----Tokenize----\n",
      "('천연, ##두, ##에, 감염, ##된, 모든, 사례, 중, 출혈, ##성, 천연, ##두, ##는, 얼마, ##의, 비중, ##을, '\n",
      " '차지, ##하, ##는, ##가, ?, 출혈, ##성, 천연, ##두, ##는, 피부, ,, 점막, ,, 소화, ##관, ##에, 광범, '\n",
      " '##한, 내, ##출혈, ##을, 동반, ##하, ##는, 심각, ##한, 천연, ##두, 유형, ##이다, ., 출혈, ##성, 천연, '\n",
      " '##두, ##는, 전체, 천연, ##두, 감염, 사례, ##의, 약, 2, %, 정도, ##였, ##으며, ,, 대부분, 성인, ##에, '\n",
      " '##게, 발병, ##했, ##다, 출혈, ##성, 천연, ##두, ##의, 발진, ##은, 수포, ##를, 형성, ##하, ##지, 않, '\n",
      " '##고, 부드러운, 상태, ##로, 남아, 있, ##다, ., 대신, 피부, 아래, ##로, 출혈, ##이, 일어나, ##서, 마치, '\n",
      " '새까, ##맣, ##게, 탄, 것, ##처럼, 검은색, ##을, 띤다, 그래서, 이, 유형, ##의, 천연, ##두, ##를, 검, '\n",
      " '##은, ##마, ##마, (, bl, ##ack, p, ##ox, ), 라고, ##도, 했, ##다, [UNK], n, [UNK], '\n",
      " 'n, ##감, ##염, 초기, ,, 또는, 전격, ##형, (, f, ##ul, ##min, ##ating, ), 출혈, ##성, 천연, '\n",
      " '##두, ##는, ,, 감염, 이틀, ##째, 내지, 사흘, ##째, ##가, 되, ##면, 결, ##막, ##하, 출혈, ##로, '\n",
      " '인해, 눈, ##의, 흰, ##자, ##위, ##가, 심, ##홍, ##색, ##이, 되, ##면서, 출혈, ##이, 확인, ##된, '\n",
      " '##다, ., 출혈, ##성, 천연, ##두, ##는, 어스, ##름, ##한, 홍, ##반, ,, 점, ##상, ##출혈, 및, 비장, '\n",
      " ',, 신장, ,, 장막, ,, 근육, ##에, 출혈, ##을, 일으키, ##고, ,, 드물, ##지만, 외, ##심, ##막, ,, 간, '\n",
      " ',, 고, ##환, ,, 난소, ,, 방광, ##에도, 출혈, ##을, 일으킨다, ., 환자, ##는, 보통, 감염, 5, ~, 7, '\n",
      " '##일, ##째, 경미, ##해, 보이, ##는, 피부, 발진, ##만, ##을, 남기, ##고, 갑자기, 죽, ##는, ##다, ., '\n",
      " '전격, ##형, 출혈, ##성, 천연, ##두, ##는, 8, ~, 10, ##일, 정도, 생존, ##한, 환자, ##들, ##에, '\n",
      " '##게, ##서, 나타났, ##다, ., 발진, 초기, ##에, 출혈, ##이, 나타나, ##며, ,, 발진, ##은, 도드라, ##지, '\n",
      " '##지, 않, ##고, 평평, ##하고, 수포, 단계, 이상, 발달, ##하, ##지, 않, ##는, ##다, 출혈, ##성, 천연, '\n",
      " '##두, 초기, 환자, ##는, 혈중, 응, ##고, ##인, ##자, (, e, ., g, ., 혈, ##소, ##판, ,, 프로, '\n",
      " '##트, ##롬, ##빈, ,, 글로, ##불, ##린, ), 가, 감소, ##하고, 안티, ##트, ##롬, ##빈, ##이, 증가, '\n",
      " '##한다, ., 말기, 환자, ##는, 확연, ##한, 혈, ##소, ##판, ##감, ##소, ##증, ##을, 나타내, ##지만, '\n",
      " '응, ##고, ##인, ##자, 감소, ##는, 덜, 심하, ##다, ., 말기, 단계, ##에서, ##는, 안티, ##트, ##롬, '\n",
      " '##빈, 증가, ##도, 나타났, ##다, 천연, ##두, 유형, ##의, 병, ##독, ##성, ##에, 따라, 이, 유형, ##의, '\n",
      " '천연, ##두, ##는, 치명, ##적, 천연, ##두, 감염, 사례, ##의, 3, ~, 25, %, 정도, ##로, 잡힌, ##다, '\n",
      " '출혈, ##성, 천연, ##두, ##는, 대개, 사망, ##에, 이를, 정도, ##로, 치명, ##적, ##이다')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# 예시 데이터\n",
    "pprint(datasets[\"train\"][\"question\"][183].split(\".\"))\n",
    "pprint(datasets[\"train\"][\"context\"][183].split(\".\"))\n",
    "print(\"----Tokenize----\")\n",
    "pprint(\", \".join(get_encoded_data(tokenized_data, 183)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%나 ()과 같은 특수문자에 대해서는 크게 문제가 되지 않을 것 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\n 개행문자 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 예시를 보았을 때 \"\\\"에 해당하는 부분이 [UNK]로 인식하여, \"\\\\\\n\"을 개행토큰으로 보지 못한다.  \n",
    "\n",
    "그렇다면 각 데이터마다 \"\\n\"의 개수는 몇개인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newline(data_samples):\n",
    "    all_lines = []\n",
    "    for i,data in enumerate(data_samples):\n",
    "        new_line_count = data.count(\"\\\\n\")\n",
    "        all_lines.append([i, new_line_count])\n",
    "    return all_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline_counts = np.array(get_newline(datasets[\"train\"][\"context\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22808\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(newline_counts[:,1],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    4],\n",
       "       [   1,    2],\n",
       "       [   2,    5],\n",
       "       ...,\n",
       "       [3949,   16],\n",
       "       [3950,   14],\n",
       "       [3951,    6]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newline_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
